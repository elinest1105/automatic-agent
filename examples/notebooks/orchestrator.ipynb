{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrator Agent Tutorial\n",
    "\n",
    "This tutorial demonstrates how to create an orchestrator agent using the Atomic Agents library. The orchestrator agent will manage tasks and respond to user inputs in rhyming verse.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennyVaneetvelde/atomic_agents/blob/main/examples/notebooks/orchestrator.ipynb#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "Before proceeding with this notebook, it is highly recommended to read up on the basics of the following libraries:\n",
    "\n",
    "- **Pydantic**: A data validation and settings management library using Python type annotations. You can find more information and documentation at [Pydantic GitHub](https://github.com/pydantic/pydantic).\n",
    "- **Instructor**: A Python library that simplifies working with structured outputs from large language models (LLMs). It provides a user-friendly API to manage validation, retries, and streaming responses. More details can be found at [Instructor GitHub](https://github.com/jxnl/instructor).\n",
    "\n",
    "Understanding these libraries will help you make the most of this library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install `atomic-agents`, `openai`, and `instructor` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install atomic-agents openai instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries\n",
    "\n",
    "We will import the necessary libraries for creating the orchestrator agent. Each library serves a specific purpose:\n",
    "- `ChatMemory`: Manages the chat history.\n",
    "- `BaseChatAgent`: The base class to create a custom chatbot. Can be extended for additional functionality if needed.\n",
    "- `SystemPromptGenerator` and `SystemPromptInfo`: To define and generate system prompts.\n",
    "- `BaseTool`, `CalculatorTool`, `SerperSearchTool`: Tools that the orchestrator agent can use to perform tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Type, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.console import Console\n",
    "from atomic_agents.lib.components.chat_memory import ChatMemory\n",
    "from atomic_agents.agents.base_chat_agent import BaseChatAgent, BaseChatAgentResponse\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptContextProviderBase, SystemPromptGenerator, SystemPromptInfo\n",
    "import instructor\n",
    "import openai\n",
    "from atomic_agents.lib.tools.base import BaseTool\n",
    "from atomic_agents.lib.tools.calculator_tool import CalculatorTool, CalculatorToolSchema\n",
    "from atomic_agents.lib.tools.search.serper_tool import SerperSearchTool, SerperSearchToolConfig, SerperSearchToolSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define System Prompt Information\n",
    "\n",
    "In this step, we will define the system prompt information including background, steps, and output instructions. This helps the orchestrator agent understand how to respond to user inputs and manage tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Definition\n",
    "\n",
    "First, we define the tools that the orchestrator agent can use. These tools will help the agent perform various tasks such as searching the web or performing calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serper Setup\n",
    "\n",
    "Set up your Serper API key. This key is required to access Serper's search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# ENTER YOUR SERPER API KEY BELOW, OR SET IT AS AN ENVIRONMENT VARIABLE #\n",
    "##################################################################\n",
    "SERPER_API_KEY = ''\n",
    "if not SERPER_API_KEY:\n",
    "    # Get the environment variable\n",
    "    SERPER_API_KEY = os.getenv('SERPER_API_KEY')\n",
    "\n",
    "if not SERPER_API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in the environment variable SERPER_API_KEY.')\n",
    "\n",
    "search_tool = SerperSearchTool(SerperSearchToolConfig(api_key=SERPER_API_KEY, max_results=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the calculator tool. This does not require any special configuration.\n",
    "calculator_tool = CalculatorTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the tool info provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolInfoProvider(SystemPromptContextProviderBase):        \n",
    "    def get_info(self) -> str:\n",
    "        response = 'The available tools are:\\n'\n",
    "        for tool in [search_tool, calculator_tool]:\n",
    "            response += f'- {tool.tool_name}: {tool.tool_description}\\n'\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Prompt Generator\n",
    "\n",
    "Next, we define the system prompt information including background, steps, output instructions and the ToolInfoProvider we defined above. This helps the orchestrator agent understand how to respond to user inputs and manage tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt information including background, steps, and output instructions\n",
    "system_prompt = SystemPromptInfo(\n",
    "    background=[\n",
    "        'This assistant is an orchestrator of tasks designed to be helpful and efficient.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Understand the user\\'s input and the current context.',\n",
    "        'Look at the tools available and determine which to use next based on the current context, user input, and history.',\n",
    "        'Execute the chosen tool and provide a relevant response to the user.'\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be efficient and effective in task orchestration.',\n",
    "        'Always answer in rhyming verse.'\n",
    "    ],\n",
    "    context_providers={\n",
    "        'tools': ToolInfoProvider(title='Available tools')\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize the system prompt generator with the defined system prompt and dynamic info providers\n",
    "system_prompt_generator = SystemPromptGenerator(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the system prompt generator\n",
    "from rich.markdown import Markdown\n",
    "from rich.console import Console\n",
    "Console().print('='*50)\n",
    "Console().print(Markdown(system_prompt_generator.generate_prompt()))\n",
    "Console().print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Chat Memory\n",
    "\n",
    "We will initialize the chat memory to store conversation history and load an initial greeting message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemory()\n",
    "initial_memory = [\n",
    "    {'role': 'assistant', 'content': 'How do you do? What can I do for you? Tell me, pray, what is your need today?'}\n",
    "]\n",
    "memory.load(initial_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set Up API Keys\n",
    "\n",
    "To use the **OpenAI** and **Serper** APIs, you need to set up your API keys. You can either enter them directly in the code or set them as environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Setup\n",
    "\n",
    "Set up your OpenAI API key. This key is required to access OpenAI's language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# ENTER YOUR OPENAI API KEY BELOW, OR SET IT AS AN ENVIRONMENT VARIABLE #\n",
    "##################################################################\n",
    "API_KEY = ''\n",
    "if not API_KEY:\n",
    "    # Get the environment variable\n",
    "    API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in the environment variable OPENAI_API_KEY.')\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI(api_key=API_KEY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Orchestrator Agent\n",
    "\n",
    "Now that we have set up the API keys, we can create the orchestrator agent. This agent will use the OpenAI client, system prompt generator, and chat memory to manage tasks and respond to user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseSchema(BaseModel):\n",
    "    chosen_schema: Union[BaseChatAgentResponse, SerperSearchToolSchema, CalculatorToolSchema] = Field(..., description='The response from the chat agent.')\n",
    "    \n",
    "    class Config:\n",
    "        title = 'ResponseSchema'\n",
    "        description = 'The response schema for the chat agent.'\n",
    "        json_schema_extra = {\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "        }\n",
    "\n",
    "# Create a chat agent with the specified model, system prompt generator, and memory\n",
    "# For all supported clients such as Anthropic & Gemini, have a look at the `instructor` library documentation.\n",
    "agent = BaseChatAgent(\n",
    "    client=client, \n",
    "    system_prompt_generator=system_prompt_generator,\n",
    "    model='gpt-3.5-turbo',\n",
    "    memory=memory,\n",
    "    output_schema=ResponseSchema\n",
    ")\n",
    "\n",
    "# Print the response schema\n",
    "Console().print(ResponseSchema.model_json_schema())\n",
    "Console().print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Main Chat Loop\n",
    "\n",
    "We will create a main chat loop for testing the orchestrator agent. This loop will allow you to interact with the chatbot in real-time.\n",
    "To exit the loop, type `/exit` or `/quit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "console.print(f'Agent: {initial_memory[0][\"content\"]}')\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input.lower() in ['/exit', '/quit']:\n",
    "        print('Exiting chat...')\n",
    "        break\n",
    "\n",
    "    response = agent.run(user_input)\n",
    "    \n",
    "    # Check the type of the response schema\n",
    "    if isinstance(response.chosen_schema, SerperSearchToolSchema):\n",
    "        output = search_tool.run(response.chosen_schema)\n",
    "    elif isinstance(response.chosen_schema, CalculatorToolSchema):\n",
    "        output = calculator_tool.run(response.chosen_schema)\n",
    "    else:\n",
    "        output = response.chosen_schema\n",
    "    \n",
    "    console.print(f'Agent: {output}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
