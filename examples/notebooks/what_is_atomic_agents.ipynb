{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAC/CAYAAAAM9BYxAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAC1DSURBVHhe7d0HlJTV3cfxq4iF2Ess5EXFAnY0Ruw9VkRjjxoVUWNXghpRFLsee+y9966g2LvE3o29YUDsBRVFI6/f69xldphdZnefLTPP93POnp2dbcPyzJ37u+V/p5jwqyBJkiRJysSUhfeSJEmSpAwYsiRJkiQpQ4YsSZIkScqQIUuSJEmSMmTIkiRJkqQMGbIkSZIkKUOGLEmSJEnKkCFLkiRJkjJkyJIkSZKkDBmyJEmSJClDhixJkiRJypAhS5IkSZIyZMiSJEmSpAwZsiRJkiQpQ4YsSZIkScqQIUuSJEmSMmTIkiRJkqQMGbIkSZIkKUOGLEmSJEnKkCFLkiRJkjJkyJIkSZKkDBmyJEmSJClDhixJkiRJypAhS5IkSZIyZMiSJEmSpAwZsiRJkiQpQ4YsSZIkScqQIUuSJEmSMmTIkiRJkqQMGbIkSZIkKUOGLEmSJEnKkCFLkiRJkjJkyJIkSZKkDBmyJEmSJClDhixJkiRJypAhS5IkSZIyZMiSJEmSpAwZsiRJkiQpQ4YsSZIkScqQIUuSJEmSMmTIkiRJkqQMGbIkSZIkKUNTTPhV4bYkKSP//e9/w4cffhiefPLJ+PG///3v+F5qLf/3f/9XuDVR7969wx/+8IewwgorFO6RJLUFQ5YkZYRgdeONN4Ybbrgh3k7o5PImtbYnnniicKu+dP1tscUWYfPNN/d6lKRWZsiSpBZK4erUU0+NH9ORpRPLLIIzCGpraRaV98ykEvqLcW1yXW622WZen5LUSgxZktQCdGD333//2HElXO23336Fz0gdRxoIYNlq8WzX8ssvH6677rrCR5KkrBiyJKmZCFeELDuqqiYErtNOO61uhosBAq5flxBKUnYMWZLUDFtttVWcERgwYICzV6pKxWHLmVhJypYhq4y0np217Nwuxv3tofRxqDo0d2S4tEoYP6dr166xE6T2lwLWtdde654WVT2CFvsJaWdOOukkr2lJyoAhq4AQU7xxPSnuJDfWYa4kBBmUGtbcMNJS7fV7K9FYlTA6QRRVMHS1vdQhdQZLtYTXJwYP4NJBSWq5XIesFKxYKsHt1HnlvVXB1BGkYM5mdWZWmUktDl9cqy7xaTv8P2y99dbuwWrAt99+G8aMGRO6d+8eppzSs+6rDe3NSiutFNuVxx9/vHCvJKk5chuyUmcJdlRVTegIcf0yQJACF9ewo8+tLy0T/OCDDwr3KCFgHXTQQWHo0KHhvPPOC+utt17hM6omaaaW10SWDkqSmieXQ428iKSAxZIfRuwMWKoWaVCAUMW1yzVM8CIAcG2rdaTS13Y8y/vkk0/C22+/HW//8MMP8X21GD16dNhmm23CWWedFf73v/8V7s0nXguZqeV6lyQ1X+5CFh3RtO+KTeuGK1UzAhfXMNcyuLYNWq3jpptuiu/dB1feO++8E1577bV4e+65547vqwWh8IsvvggjRowIX331VeHe/Dr55JPjwI1tiSQ1X65CFi8YaXmVVcFUS7iWmdliBJqglc6/UXb4mxqwyhs/fnxN7OFh9XyOtynXYfCGtsR2RJKaLzchi6UPaQbLErWqRXSMGIEGAwqpaIZaLnU2nfku7/XXXw/33HNPvN2zZ88w88wzx9vV5uOPPw6ffvppnNmiyAyvG0899VS8/5dffil8VT5wraf9n5KkpstNyErLHhidczRatYqgxSACnaOBAwcW7lVLUdkR/H1V3/fffx+uvvrqMGrUqMI9IUw11VSFWx3bzz//HD777LPw4osvhs8//zzuKaNgR48ePcLKK68c9+7yerHccsuF+++/v/Bd+ZDO6nPJoCQ1T26qC84777zxPUta7Cip1nlYbrYoa83f0aIX9fHycfvtt4dBgwaFJZZYIkwxxRThyy+/DGeffXZYYIEFCl/VsRAKKXBx5plnFu4p73e/+13o1atXWGaZZeIbQWv66acvfDYfaEcYsLGce9tIM4dpwIKPmVGVWlsaVEk4xoi+sv2HlslFyNp///3r9lPYSVIecL1z3XvNZ4NBGv6OzoLX995778VlZVTnO/744+Nsz7PPPttqIYtlfD/++GMMQM2dLXv++efDtttuG7777rvCPRP9/ve/j/+eNddcM8w+++yhc+fOhc/kE7NYLLP3yILWQYjiKA6CVdovnqTBYAeF1Za4JnkrxjXIa5/L5ZsuFyGLUWguGmexlBdc74xCw1HolkmB1fajPmaEjj322HDFFVeEAw88MPztb3+LQauxkMW+po8++iiMHDkyzDnnnGG++eab7KHFfA/LNS+44IK6JXuELF7wt9tuu9ClS5d4H/i5hC+qGzKrxtldJ554Yrj00kvD3//+9/g9PO7DDjssvPDCC2H99dcPq6++ephmmmnCMcccE0NcR56Fa2t0/lky6Yx4tgivtCupM5s6scwewL+12hvXJs9/2t60Jzldp5tvvrmvhRXKxZ6s4oZMygOudV6oU0MpZYm9TJdddlkMWOuss07YbLPNwtRTT134bHnvvvtuDKsrrrhi7LivscYaMewQehpC6GFpX//+/evtiWIWilB09NFHx6/B119/HYYMGRL23XffMGbMmPgYzznnnBiwwAHJFOdghur0008PjzzySDj00EPDKqusEhZaaKEw00wzxa/TRGkJUdqTqJYhXDErnopwccYhs4QM4DAAQJttwFJHkAIVKzi4PrlWwbXrmZyVq/mQlRK4y3yUN2lQwQ5SNhykmYjzpM4444zQtWvXsMcee4S55pqr8JkQZpxxxnqzS8xE3XbbbeEvf/lL3VljydNPPx1ntlhQwaxTcQU/QtIll1xSt9z1kEMOCS+99FI8i4sXeH73o48+GsMbmI1iBuubb76JIeyOO+6I31/szjvvjJ9ntqt4ueF0000X/3+pLMjj0G+85rORVhYUh6sUrKSOjnaAa5VjYrh2uZ7pWxu0Ji831QXTNLyUF17z2SiumqcQK/ClowIOOOCAsNRSS8XbhKJx48bFfUzFe5nuu+++WBiDQ37XXXfd8OCDD8a9XLyxH4WR/csvvzwWlmB26qefforf98ADD9QFOYpU7LzzznG2iQBHkQ3CHBUB00xY+v28Z3kbv5PHwawVv2fBBReMAS2tbCiHn5dmxvQbg1bLsJKALQvsueJvybVpuFI1SmErbUFg0IDVCWpYzYesNIrvFLzyJi31cblgy9Apt6P5GwLNhRdeGPczsQeLpX8s0/vPf/4TO4+0t7wAr7rqqnEpILNUBBxmllhNcNxxx4Xu3bvHfVi8zTDDDHFmiaWAfA0h6X//+18MO9dff328jzeW/BG0HnroobgEcJdddomBiTLraf8U4SyVYWf/Fg4//PCw0UYbhSWXXDK+BrBn65NPPomfU+UaC6ZqWNrTBo6P4blhX0TVjtdDZrV474xW43Izk2UnSXnDNe91nw3/jhP3YV1zzTXx43PPPTfOPlHmnAISRx11VN2s37LLLhvv43s4hwr8DUv3PbE88OGHHw7PPPNM/JgRf5b9sYzw3nvvjVX+2O/F55k922GHHWJxDZYILrLIImHXXXetO/iYn0VAS/bcc8+w4YYbxjDHz+TrQRBrCoIZSxXff//9wj354rXfPATTNMpPwKJTKtUK2oXioOVgbnm5CVmSpOYhLLGfiuV7xajyR9Cich/L8ghFIOAwYk8FQc6YAktLqNzHTBMzXISovfbaKy4/YbZqgw02iCFr/Pjx4bHHHovfQxWrwYMHx7O49t577zhD1rdv33DCCSeEq666KoY5qgiCGbUUoMoV4+jWrVt8X275J8sKU1jjnK9iBL4rr7yybolMHnlWU9NxGHyaBTdgqRala7t4QEH15SJkORKnvPLab7m8dzAJWBdddFE44ogjYhhhCR5LAwlCL774YhzFPPjgg8PGG28c1l577fg9aXkZIadfv3514YvZqLXWWiuO7LPHiuIUSZ8+feJMF0sSmT2abbbZ4vXLTBT7qXgRp5ohQY8iAny+GCGL7yP4cQ4WAa8YVQXnn3/+8NZbb01S3KJTp05h2mmnjbdZvpiwP4uS9Cj9fVJDGNVP514ZsFTLaKMpTmTQKs+QJUkqi4DF/ibOw2Kmh/cs2WOWij1/xQUuWKqXZokoapEqBVK4ghfhffbZJyy22GLxPiy99NJxOR8HALOUr0ePHnFWip9JoGFWiqWExUsAGzPLLLPEn8NMF7NraYYr4fEuvvji4c033wwff/xx4d6JUkVEOsh0GFgeSCi89dZb4ywbwVCqRKqiyT5E+x+qdVzntI8uGZxUzYcslzlIUvNQ4IKZI8ILm5vZZ9XQ4cGEqh9//DHephR6ug1CE8unKKHOuUC8EV522mmnWIiCgJVmnqaffvqw2mqrxdvMXBG0Kjkzn4ONOQuL5YfFJeQTfu6OO+4YqxkWh8OEpYjMmN18881x2SKP4fzzz4+Pa/vtt/ccLVUsHR1jFUHlBdc6g1Pp2tdv3JMlSSqLvVLsbeK8KWaHGgpYILhssskmsXoggadckCnF3iwQbghBCXuqqF5IAGO5IQcSE9xS2CLQMWtGIGL/F1UO2RPGksDiM7tKsYeL4JT2ZxWjSuGWW25Z+Oi3GTiCIUGPUdrSmTGpnNTJdBZLecLqBtpJqslqIkOWVMPS3hg1H3/DVA4/b5jNoWogh/xWgvOrOAdr9913r3fYb0PSsj2+rzjEMBPF+n6qB+LEE0+MAYnwxkwUe6sIVhyMOWzYsPg1Cy+8cEUzXg1hX1b//v3D8OHD4xszaCxxpKOc94BlO9J0nlOovCFo2VbUZ8iSapyNnjoi9lp98cUXoWfPnmVDHHvAOFCY4hjMplHQohj7u6g4SBEOvoaDjlsahgiGiy66aHyrZCYuD2w/msazOZVXDCzQXrg3ayJDllTD7CCpo+LgYZYLssSPt3JYnkixilNOOSW89NJL8Y19Yhx+zP4uZrvozFL0wuV86ghSB9OlgsqbtOIjDTQoByErr8t8JKmjYP8UpaxHjx5duCfEwhjsuZpnnnniYcGTwywTxScIVKWzWlJHQbiyEqXyiGufNwd3J8rFTJb/4ZLUPsaOHRuOPvrocOCBB4ZDDjkkFrAAAYvwNeuss9adUSVJql7O4NbnckGpRjm4kA3/jtl54IEHYsW+559/Phas4DwtlgpSdEKSpFpiyJJqVDojzpCg9jTDDDPEWay11lorfkzVPkq9n3nmmfEg4mWWWcb9VJKkmmPIUtXi/Jo+ffqEd999t3CPpI6IkuvnnntuLMVO1cCEioAcdKyOzYEaSZVKA7wyZNU8Du187bXXwpgxY+LHP/zwQ7jgggtiVa5zzjknHHvssfHQTw7y/P777+PXVIsvv/wyvPzyy3HpkaSObeqpp46H/aaS7Nzed99945lYkiTVGkNWDeNgzqFDh8YODecXcIhnjx494iZ0TqU//vjjw3nnnRceeeSRcPLJJ4dbbrml8J3VhfN2JFUHNkZTkp1ZrTnmmKNwr1Q7nPlTnlnVeyJDVg37+eef47ky3333XeGe+pZeeumw6qqrxiU7BK811lgjBrNq88EHH8R/KzNbL774YjynhHN0mLWTJDWf1cIkqXkMWTWsc+fOYffddw/XXntteOyxx8KIESNC37594+cGDx4cZ67Y13T++efHJYOcV1MNG9AJjW+88UasTAY20C+wwAKhV69e8d+39dZbh/XXXz8MGDAglo/OK0dTW86/oSRJlfE1s75chKw8/6dTHnmFFVaI07ezzTZbrPQFPq6mil7PPfdcWG+99eKSx0UXXTSss8464eabby58dqLu3buHLbbYIhx11FGxVLSHlkqS2pIdTUlwJitHWArI/iXKJs8111yFezu+H3/8MQYqCniUs8EGG4TbbrstvPLKK/EcnpNOOilsv/32YcEFFwxTTuklLklqWwYtSfZAc4Q9Sh999FGc0ZpxxhkL906KMPb222+Hzz//vHBPiNUJ99hjjziTdMkll8Q9UKVGjx4dDjjggDjTtNRSS4Ujjjgi/pxy+7yoZPjMM8/E75ncPjCqki233HKx9PNKK60Ui3TcfvvtsUIiFl544fj7mKXzvB2Ba4Nr5bTTTrOzI0mS2pwhK0cINt9++22cySo+q6YUhST222+/cPjhh8ev5+2EE06IpZdx9tlnh2effTbeTig4sdNOO4Xrr78+7pn66quvwsUXXxwPIP3Xv/41SRGKq6++OlY9JJR98cUXhXvr4/EyK3XPPfeEjTbaKDz11FPhqquuCptvvnkMVVawUUO4tnDqqafGsJUClyS1Bc8KkmTIypFvvvkmBpq55547TDfddIV7JzXTTDOFWWedNX4tgYniGDfddFPhsyF88sknYfjw4WH8+PHxY8IQX1O8nG+11VYL/fr1i2GOji5nc6XZLwJXOkB4zjnnDNNMM028XYqwN2zYsBisCG18XfFMVap69fXXX4effvop3pbAPsTrrrsuhnSuE2azUuDaaqut4hEGklTKme+mo59ARV9e18utcsnagw8+GFZZZZXw5JNPFu7peKrhMbYGnz/1GbJyhIaQinzsx5p22mkL906K8MQ+qHHjxoUzzjgjnqdFQYlrrrkmnHXWWXEm7NVXX61bTvjOO++Ehx9+ON4G1f2Y7RoyZEg88Lhr166xs0tgAoGIcuugEWqoOAWNNo+Xx9rY3ioep2dlqRThiiIoKWwtv/zy8QXgiSeeqFtOyHtK/ksSGIRJbYODMeUxUMq2AaoSsyeaLQJU9OUYmCWXXDKuUBk5cmSrHQnDwCo/n4rJrfU7WqoaHqNanyErR9iPhW7dujW6d4kwRgPBkkBmqAhJxxxzTJwdIBQtvvjicY9WCkrvv/9+nN0CAWzLLbcM008/ffwdfM/ee+8dP3f//ffHpYeMdPE70FDZeH4/Xw9+Z2N7yKTGFIetxx9/PN4GgYtOFIMCDS0ndMmPlC+0E7QRPPfTYEya/W7KgEytjuizqoStBLw98sgjccC1GK/tbBvgdZstA2nFS2tgcLWjB5hqeIxqPVP8+p9f0//7aTSKpWd5x7K7gw8+ODaAvXv3Ltw7KWamKHLx+uuvx1kmAtbGG28cZ5NoMCg8wYxW+jncZs8WVl555XD66afH4hpJ+nnMSHGmFQFs3333jbNfnOFFECvGJckoGYUzcMopp9TtsSlG4Qzup5NMg5+WQPIY+T9nNm677bYLnTp1ivfnDX8Drn+kYFGpphxASghvDaNGjSrcar6GOjoscU2DA59++mnh3hC6dOkS5p9//jDffPPF2+n64u/HbJiUNwQMZn8ZoGhKu1ALaD8IVjfeeGP8G4C/Aa9ZtA2lr11Ify/ai6a2ux0d7eaxxx4bB1+TddddN/zzn/+MRbFAsSvO3kxbDHgN4rzOqaaaKn6chVtvvTX2IdifzWs/CMUMztJus/ImHVfTXqrhMbYGrgNfLycyZOUE/82M1PM2uZCVwgtYDnDQQQfFYJSksEZBC8JX+rkgXLHEkNG/JIUssIyQTvmRRx4Zf85f//rXcNhhh8VGBzxOXtT4f0ud7BNPPDHOjpViDxiNN9UFeUKn2S6WMe6zzz5xxozAx76vPCoOWWoeBgEMWR0Py5VYvszRDc8//3xd5VHaiRVXXDFWJFU28hyyijUWuHg9TYGqVkMWr81U9R00aFDdShT2XhMgCAzFmL2iuBWDr3wt/YNNNtmkxdV/ed4zKHb55ZfHINeQP/7xj7Ef0loDgI2phsfYmgxZ9RmycoKlfYw23X333XGGqEePHnEUnxLqzPRQrY8nPaNNQ4cODXvttVc8Z4ogxfLAYo8++micIdptt93iUkBGthi1YaaKgLPIIovE+3r16hVHvih6QSPLixHv2RNGxUAqGNIA77DDDqFPnz6hc+fO4c4774zhC0sssUR8sdp0003j4cLFQQ9ssiW8UaSDMMXBy2CjKY9/6aWXjgGNQh55VByyCAvNkUUFRzoiTVk6U8kSvUp/XiWzYW+++eYks1pci1w///jHPwxZrYiXHwZhuD5ZHsxzerHFFotHNvTt2ze2IaX7MenA0aak2fNSfB9tXZ4DQZaqNWQ11kY01MY09D2l7QhFpPgZ7BtO38NAIcvlU4EpXu+a2+52RPw7mZlhEJbZKwZfmfFvaL80g5w8T9nT3bNnzzjAusACCxQ+Wzn2ZTMQy9LExhBWaLNpM2g/aEeynD1rTDU8xrbANcJgl6+XExmyatjYsWNjaGFZHi+QrKVuCMGIRpARKRpRNq4SbspN8/OCQ+eT+wkxLAFk/xaNLqM3HAhcisblkEMOiZtjaZRpgFlOQOBLo2IJo9J8LZtpadRZfnDllVfGNd7FeByEPDrILGmk0aKUPEGO72GZIS8GLR09q1aMuhIQ4HLZ+ngxYESav1EalQadSF4gGABA+hv6opE9BmTohNFmlLYByZprrhnbCPaRJsUDNMy08xynLWIgif9TwhrtzXHHHRdH2tUyKWTRXper4lppMCnW0Pc0NsBS7nsa+jkdwTrrrBOv71pAN/HCCy8MRx99dAyPbBmoZAaGpXH0JRjc5TV91113LXymcsXbEUrxWBhQJawwmNpYgazWVA2PsS3wfDRk1WfIqmFpxqkcggyzV1QCSu/nmGOOugaAJwv7sWaZZZb4cSmWDTBqQwPKbBchi5DGcsFzzz23ruPEz1hvvfXiGVqEpuIGhkvvhRdeiFPmdIyo/rb22mvHM7HSEj86ufz8PffcM6y66qrxvoS9VwQqZrFK7bjjjvGxlc5+5Ykha1Jc13TEKedejHBFx50Xh2KGrNbBwMjAgQPjgA5oJ3beeee4fBj83S+99NI4aMKMOh0YZtopnHPooYeGm2++uexS5l9++SXOZLNUifZkm222ye0gS1ZSyGIEnqWZTdXU2S+eo8XfUxyk0v3F97UnHg+vQ7zW8cbtZMCAAXWDNdWOmTn+LTxfeZ1n8KLS5xWvz4SywYMHx+c4r/tvvPFGfM9S/8nN5PB85nnOdgC2J9BXSe0HbXPxfuzGsIyPdoGwyAAAZ3huv/32ZZcX0460x2OsdjwvDVn1GbJqGCPFhBD+i+mogI2WjA4TsrLofNBwsb8qhay0HID7KTxB52lyDVRLME1P409YQ2o46WA1VqY+DwxZv2koWIGOEBuTG+oIGrJaB531bbfdNnZMGRGnDVl99dXrtRUsC7zlllviTBaz1Pz96cSy35JlhQzmELzUughZPA+WWWaZSc40TGGn3POnNAhlHYxKf2fpx6VLncs9xtLZmKb8DF5b6VsU/w1oJx566KF4fddSyEr7n1nqn5b8V4LnayqUlQpYvfzyy3HQleXZDe0Pp8/CKhyWEhPMaBd4S4O0ad94pQGGWW5m4XgdKEV/iM8VXwvt8RhrAc8FQ1Z9hiy1SEMhqy0RJhk1YkkR+7Icuf5NCgi8+LNcNG/oDPA3KF0OyBtLOCrpABmyWkfaT0nnjeXGG264YdllNCwrZkkygeqyyy6Lz3G+j5et9mpv8obXUDqa5UJWUm7vZnEgKTa5YINKAlJ7oBNZOmDDY6N9SO1JmvmrpZDV3MCQZsB4nrN0kr1IqeoeA78899mqUKp4xpplqssuu2zhM79J7QftAe3y5I54oSz/gQceWPgoxG0RDMg+9dRTcbacoMVsOat50B6PsRYYsiY16auaVGVYosiINg2kAUugwhEdIRp9ZjXp8LAJnbDJC26tdH6qHRviS5cRF+P5nI5gYE8ps+MM7Kht8f9AZ5PnTrk3OlSlbzzHyr3RASt+Y8Cj9I3gUvzW3mhHCJt0IGlXeEy0KQze0qbw78oDClkVL4mcHEIMe8JZappKvH/22Wfx/Z/+9Ke6+0p9/PHHsagIhUSKZ7dLMRNebp9gMfamM7uYEJjOOeecuHyR6n/snWMfOf+vqW1p68eo2mXIUovQAcrDNHg1yqIyYLWik1caqui8qWMgVNExodNGcCqH2Sr2lTKqzCgxo+B0WFgirLbXEcJOW2Mmm2DFG7cJVrQplQQrglmtYIUI1X5HjhwZl95VguJThBlQ8IotCuA5D/Zdl+s78LwnmHFOJ/ulWjpbzUqX4oIqlJJnnxVY9kgRL2asaGuYfUJbP0bVLkOWWoRS11TMobGptPGVWlsaIVfHNM8888TgRKeN5YAEp7RyndFk9lgOGTIkLrcBG8iLR5Rtb9SaWGpMsGJ5HFK4IljlMWyyWoRBO56XLIVMz9WGsE+JvZR8PVWKWZpXusqEGbFyP4f9UBSnAPuqG5slKufee++Ng2xpVop2IoUnMKtWPHNOGfrUFvFWrK0eo2pXLkJWHhvFtpTKKzN1LkmTQzUv9q6wdIelOhS9oLNDkOIMPyp0sQeLEWY6vCz5LO2kuc9WrYHrLS0JrHTWqtZRwZM9eWDvErPL7JcsRbEaDginEATVh6kITPny4v1Iqb9w33331Qs/GDNmTKw2nMr/U+WvXMihoBaDu+yLSrNOGDduXPy5w4YNq5vx5jExA54wI1nusSN9XVs/RtUuZ7LUYrwY0aCw/pqDGCVpcghYF110URg0aFCcNaANAZvS+/XrF5d7UnCByoJp5HmhhRaKRTIIX+zlkrJGtVECPMuMWzJAW0uDuwxwsOSPGR8q7hE6qfL59NNPx5kiyp1TnIbjV1L1T86v4/zK0qV0/AzeKIbBvijOvWOA9qqrropHOPAxs00USOHnlxtMYZCGIiwEGEJL8tFHH8VCFoSbdLQD94G9UyBA83/LLBJhixDNUkHan1T4oq0fo2qXIUstxqgPDc7QoUNj46GOwRlcdXR0Unbbbbd4fg2dGDorDz74YKxgxnLP0mMY6JjQcaOyIDNeUtZsN8vj78KZV4Qn3HHHHTGQsleS4hEc/s0yXvZeUXWPGcE0I1SMn8Pzm+9jVmmXXXaJAe7ggw+O4Yzz7/g97HVipod+RWmxDZbnEYrY98XyRfZdcVYVpdgJRoS90iqWVAtk2Sf4XbQfBMD+/fvHWakddtihbrauvR6jao8hSy3G6A9rrkFDoo7FToNqCQek00FqqCKhpNZBKKDKJEt5+/TpUxcSmH3u27dvXErIUjiCS5cuXeLnyqGIBnuaCC+EsjR7zRI6wg3hjIIUW265ZXyely7H47xPlhiDQEc44mvvv//+ONPNYyttHyhgwdJFwhG/L2GmnEEbQljxzFJ7PEbVnlyck8VIBFPCaj2se2bTKA1P6enpaj8swyJksTxCTUfb4TlZyjPPmmyaWjwnqyNiQJelxnfffXf8mLC03XbbxQHf4rCUzrxKhyGDZYLsv2I5X+lseZYqfYy1wnOyJpWLGO1IfusjWLFPwoAlSZJaExUPCU4cBDxixIg4kEjBnErCC0v5WHrcmgELLXmMqg3OVUo1zAEGSWp77rdpfYQVClTwt+6oS++q4TFmrfhcsrwzZEmSJKnmpKqlUnuo+ZBlopYkScofCuUgnWsltaWaD1mcUi7lFRtRJUnKo1lnnTWeyffWW2/FM6uktuRyQUlSblFglypgVByTsuJ+2I6B8uscRPzCCy/EM63UerzmJ2XIkmqYM1lS4yhNzkGkl156aeEelbLz1HSuoukYqCK41FJLxSNmhg8fPsmhwVJrykXIsqOpPErXvde/1LBffvklzmKNHTt2kgNFJVW3Tp06hT//+c+xut9XX30Vfvrpp8JnpNZX8yHLETjlFQfpqmUcjc6PMWPGhB9++KHwkdQy9j06jiWWWCJce+214YADDmj1s7Hyzuu+vpoPWb17944j+Y7mK2+efPLJ+H6FFVaI7yVJypspppgidOvWra7SoNRWaj5kpZFoS7krb5zJkqS252i+8sprv77cLBdMo/pSHhTP3jKbK6lx0003Xdy/IbWUHU1JyEXhi+WXXz7ccMMNhY+k2nfaaacVbrlcUB0DG86//PLL8PXXX8diEx3Fd999F0u4U4Wsc+fOhXtVzNAgqVLuZZ4oFyFrv/32i6P6Lp9SXhQPKthBaj7/dpWjaATLsh9//PFw+eWXh4MPPjiWTp533nnj24ILLhh69eoVllxyyTD//PPX3b/ooouGK664ot1KK//444/hk08+KXwktZx7wJVXXvv15SJkkarpLBWP7ku1av/99y/cCuGkk04q3JKyRahi4OrUU08NW221VejRo0dYeeWVwzbbbBMOPfTQcNVVV8WSyZPDTNJdd91V0ddKHR39DTuayiuufbcoTJSLkEXAcjZLecD1XTyL5VLBlnM2q77vv/8+nHvuuWHNNdcMW2+9dRy8euKJJwqfDWHppZcOq666aujevXv8eMMNNwwPPvhgeOGFF8Irr7wS3n///XgAcPHbZZddFpfrtSf/n5Ul+xrKmzS4YFs6US5CFuhs8h9fPMov1RIaODq9yYABA2zsMuDfsD7Ok7r11lvDqFGj4sfseR00aFAYNmxYeOONN+LnWP631157xc8TulgeSPnkGWaYIZZTLjXVVFPFt/Y05ZRTln1seWdl3uZxNkt5kwYW3JM1UW5CFh2lk08+OTZ8LG2RagnX9cCBAwsf/dbxZfZW2bCjOdFcc80VB62WW265OKNFoNptt93igZ/FB32mSn2zzjprhw4vH330UeGW1HJpUObGG2+M76W8cWByotyELPAfzx4VlrastNJKTuerJnAdcz2nJVtc59ddd128LWWtS5cuYciQIXFZ6vrrrx+mnnrqwmfq++yzzwq3mo4qhCwhZECM4hgrrrhi2HPPPcPtt98elys2pDnflwpu2DFomCPTlUv7UZzJUt5wVNIWW2xR+EjIVcgCFwDLqNLSKpYPGrZUjbiG2Q9TvESQGSwDVraYtbHD1HSNhaGGjB8/Ptx2221h0003DYcddljdwAFLE1mOuPfee4e11147PPDAA/XKwDf3+zBy5MjCLZXjtd80KZDyd7NvoTxh4M2iF/XlLmSBZVSUGWbkkouCTiozAXRYbRTV0aVwxTVLZbeEwQMCliPyqkZUKzz++OPDPvvsE959991437rrrhuGDx8ennvuuXDttdeGvn37xuDUr1+/OGP1888/N/v7VBnaG9uUyvG3Sn8vKxorL1LBLYtt1ZfLkAUaQTqkdEzBCwkd1hS4mOHioiF0OZKn9paCFcugisMV1zHXMBXa3IPVOrp27Wob0AY4r+q9994rfPTbYNgpp5wSz9GabbbZ4ov36aefHpf+cd7WGWecEZ5++ulmfx9YKkhI69mzZ5h99tnjfZooXfc8B1S5tGSKGVUHbpUHLBWEAzL1TTHhV4XbucULCQ0hG1XTMpNS6cLxAlJb4bos17nnGuRFnI6P659bH20Dgy9p9luVIdhQbIjAs9lmmxXubRhh58gjj4zna22//faxYiH7v8p56KGHwg477BALbrAU8Nhjj23y9x1wwAFxRovf+eyzz4azzz47LLDAAoWvFBhoZMCR2UBHqCtHu81gGFzCrTxgDyz9Ec/mrM+QVSJ1aulYpWRerLEqY+U6xGjofqm40158Ox2gnRCo+NiOTttLHSY7mk2TQhYzS7xNrsJgcciaXDB79NFHw3bbbRe23XbbcOCBB4YTTjihyd/H3i0YshqWQpYDDE3HqoM0aEvH0wEx1SoHYxpmyGpnkwtgkysdXUmAS+fZTE5zw2C1lreutGJWY52LcstoSr+++PfYUak+KWSxLNMlmZVrashi2d9RRx0VS8LznlmpcmjPBg8eHAfBCFWrr756OProo5v8fezb4ncSsu66665wySWXhKWWWqrw1UJaNs9yZDUN7QZBi/e0++6XVa3i9TFd4ypByJIkNWzLLbeMb6rcBRdcMKFbt24ThgwZMuHXMFO4t3HDhw+P37PCCitMuPfeeyf89NNP8X7ef/jhh/Fn/hqq4teceeaZdT+3ud83bty4CYMGDYr3jxgxIt6nifi7DBw4sPCRmoprir8hbyuuuGLhXql20D7YfjYst4UvJKlSLIFo7kxvXjFLhNGjR8elgJVYeeWV4+g/s079+/ePy/dY6897RkuZqfriiy/i7BOfT2d0Nff7ODyZw5Xx1ltvxff6DTNYahnajeLiWlyLtiOqFWyroZ1g36HLBMvrdPivCrclSWVMmDAhXHzxxfHFxINZK0O4YhkeBwKvttpqoXPnzoXPNIzwQ0eUan+dOnUK3333XRg7dmyYeeaZw1prrRWLXBx66KHxBX2qqaYqfFfzvw8Uv+BxctYWYa2hohl5c++998Y9RTvttFNYbLHFCveqqWgzWCrL3/Kbb74J99xzT5hxxhn9m6qqpYJQYM+mynNPliRNRhqFtlJY5TiMmI46IWuOOeYo3NvxELJeffXVMG7cuFjindkt/bbPguve/VjZ4G9ZvEeLwM9eRfdpqdpwnAzHyHDtUtTFWayGGbIkqQKpWpgVlFTrUrUwSzJni4DFUTHF5xzyN+7du7dtijq0cteuM1iTZ8iSpAqk5RF2PFXrHFBoXaUdVqTZLY4gKD3CQ2prXKPgOkXpwICVditjyJKkCvCiM3DgwPjeJRKqVWkWy6WxbYP2hAEcOrPpXC2kkGXYqm4deQ9vueN3UrhK7xPDVfMYsiSpQqkDyguO596oFqW9WB6g2/ZSx5bOL7c5061az6HMSmlnX5VryutTaRhM3+tS1pYxZElShXjBL9687pp01ZK0TNBZLElqOc/JkqQKpRkspMAl1QIqhhGwiq9xSVLzGbIkqQnohKbCF3RK0/IqqVqlksywqIskZcPDiCWpiThItPSAUQ6/JYBx0KhUDRgc2GWXXWLRBa7d888/3/0XkpQR92RJUjOlQhgJHVU6qR4yqo6O2Suu37S/0EIukpQtQ5YktQCdVEq7F5dfRgpcnHvj7IA6Aq7V0vOZBgwYYFlmSWoFhixJygAd2DQ7UCrNEKSwRVlcdISZAx53LRg1alThVtN17dq1cKtjyPK6oAw4/8fF1yU/3zNvJKl1GbIkKUN0aDlcNJ1xUzrDJbW1NKvKe8+9kaS2YciSpFZWPFvUnMNFW3u2qSWzQO2lo80+lWqPWcrSA0XRHo9DkmTIkiRJkqRMeU6WJEmSJGXIkCVJkiRJGTJkSZIkSVKGDFmSJEmSlCFDliRJkiRlyJAlSZIkSRkyZEmSJElShgxZkiRJkpQhQ5YkSZIkZciQJUmSJEkZMmRJkiRJUoYMWZIkSZKUIUOWJEmSJGXIkCVJkiRJGTJkSZIkSVKGDFmSJEmSlCFDliRJkiRlyJAlSZIkSRkyZEmSJElShgxZkiRJkpQhQ5YkSZIkZciQJUmSJEkZMmRJkiRJUoYMWZIkSZKUIUOWJEmSJGXIkCVJkiRJGTJkSZIkSVKGDFmSJEmSlCFDliRJkiRlyJAlSZIkSRkyZEmSJElShgxZkiRJkpQhQ5YkSZIkZciQJUmSJEkZMmRJkiRJUoYMWZIkSZKUIUOWJEmSJGXIkCVJkiRJGTJkSZIkSVKGDFmSJEmSlCFDliRJkiRlyJAlSZIkSRkyZEmSJElSZkL4f+cyzpxOWESZAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Atomic Agents: Building AI with Modular Design\n",
    "\n",
    "Imagine building AI applications as easily as snapping together LEGO blocks. That's the idea behind [Atomic Agents](https://github.com/KennyVaneetvelde/atomic_agents), a new multi-agent framework inspired by **Atomic Design** principles.\n",
    "\n",
    "## Before we start, a brief background on Atomic Design\n",
    "\n",
    "First, let's talk about **Atomic Design**. Created by **Brad Frost**, it's a methodology for crafting design systems by breaking down interfaces into smaller, self-contained, reusable components. Think of it like atoms, molecules, and organisms in chemistry, but for UI design. This approach helps in creating scalable and consistent user interfaces while also allowing to modify/switch out any single part with minimal impact. Another analogy, as previously mentioned, is LEGO blocks where you can combine all the different, simple pieces to create something completely new and complex.\n",
    "\n",
    "## Why Atomic Agents?\n",
    "\n",
    "A lot of existing frameworks and methodologies for **Agentic AI** are focused on building autonomous multi-agent systems that you basically wind up and let go. While these can be fun to demo, they're not always practical for real-world applications. Real-life companies aren't looking for a bot that writes articles in a different style each time, with a different structure and a different tone. They want a bot that can write articles in a consistent style, with a consistent structure and a consistent tone that aligns with their brand. Beside fine-tuning a model, which requires a lot of data and money, and isn't even possible if you really want to use the latest GPT model, there's no practical way to gain full control of the output of these frameworks.\n",
    "\n",
    "In business, management rarely allocates budget just to create something that's cool but has no value. They want to see a return on investment. They want to see real business issues being solved and automated and cut costs. To achieve this, you need **modularity**, you need to be able to control the output, make sure it's not a black box, make the output reproducible, and make it reliable. This is where **Atomic Agents** come in.\n",
    "\n",
    "So how are these business problems solved traditionally, pre-AI? Well, before we even start writing code, we usually start with flows, user stories, customer journeys, ... and then we start breaking these down into smaller parts. We then start writing the necessary code. We'll have a function that takes in some input, processes it, and returns some output. We'll have another function that takes in that output, processes it, and stores it in a database. We'll have another function that queries the database, processes the data, and returns it to the user. The aim of **Atomic Agents** is to bring this same level of modularity and predictability to AI agent development.\n",
    "\n",
    "In other words, we are not looking to build \"An AI system that writes a blogpost\". We are looking for something highly structured and verbose. Specifically, we want to build an AI system that:\n",
    "\n",
    "1. Generates queries related to a subject\n",
    "2. Identifies the top X most relevant articles\n",
    "3. Visits each identified article's page\n",
    "4. Extracts the text from each article\n",
    "5. Generates a summary of each article\n",
    "6. Stores the summaries in a vector database\n",
    "7. Generates X questions around the subject\n",
    "8. Uses the vector database to answer those questions\n",
    "9. Re-synthesizes the answers into a coherent blogpost\n",
    "\n",
    "This approach; while being a lot more verbose, is also a lot more predictable, reliable, and, more importantly, usable in a real-world business.\n",
    "\n",
    "On top of that, we want to be able to fine-tune each individual step of that system if necessary, we want to be able to modify the system prompt for each task individually, be able to modify which tools are used, and how they are used, be able to choose where memory or context is shared, ... This is where **Atomic Agents** come in.\n",
    "\n",
    "## Anatomy of an Agent\n",
    "\n",
    "AI agents, not just in the **Atomic Agents** framework, take input from several sources, such as the **system prompt**, the **user input**, the (optionally) **available tools**, and **memory**. Within **Atomic Agents**, I wanted the developer to have full control over how each of these affects the output. This is why each of these are separate components within the framework. In developer terms, we speak of \"separation of concerns\" and \"single responsibility principle\" here.\n",
    "\n",
    "![Anatomy of an Atomic Agent](../../.assets/what_is_sent_in_prompt.png)\n",
    "\n",
    "In the diagram above, you can see the different components that make up an **Atomic Agent**. Each agent has a \"run\" method, an input schema and an output schema, each with their own schema descriptions, property descriptions, ... all defined by the developer using **Pydantic models**. This enables us to dynamically generate the input to the agent, and to validate its output. This is important because it allows us to chain agents together effortlessly, all the while ensuring that the output of one agent is the correct input for the next agent. Thus, in the schema all the green boxes are things that are always sent to the agent, the blue boxes are sent to the agent in the case where Agent1 is chained to Agent2, and Agent1 must generate output using the input schema of Agent2.\n",
    "\n",
    "Tools have almost the exact same setup, each tool has an input schema, an output schema, and a \"run\" method. This allows us to largely treat tools and agents the same way, and to chain them together in the same way. This is in line with a personal philosophy of mine that, at least until we reach AGI, we should treat AI agents as very advanced text-processing tools that are part of a bigger pipeline, rather than as a completely new paradigm (See [my article on Defensive & Robust design in AI automation](https://medium.com/@kenny_v/defensive-and-robust-design-in-ai-automation-8e951c8e7fd7)).\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The real fun begins when you start chaining the input and output of different tools and agents together. By simply assigning the output schema of an agent to be the input schema to a tool, or to another agent, you can create complex AI applications that are still modular and easy to understand. If at any later point you change the tool, and change the schema, the entire system will still work without needing to change anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Building a simple AI agent\n",
    "Now that we've covered the basics, let's build a simple AI agent using **Atomic Agents** and examine how it works under the hood.\n",
    "\n",
    "First, we need to install the Atomic Agents package. You can do this by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install atomic-agents openai instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or better yet, you can clone the repository from [here](https://github.com/KennyVaneetvelde/atomic_agents) and help me improve it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import the necessary components for creating the chatbot. Each component serves a specific purpose:\n",
    "- `AgentMemory`: Manages the chat history.\n",
    "- `BaseAgent`: The base class to create a custom chatbot. Can be extended for additional functionality if needed.\n",
    "- `SystemPromptGenerator`: To define and generate system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the system prompt information including background, steps, and output instructions. In this example, we will define a system prompt that asks the chatbot to respond to user inputs in rhyming verse.\n",
    "\n",
    "The structuring of the system prompts in this library is loosely inspired by the concept of **Patterns** in the [Fabric library](https://github.com/danielmiessler/fabric/tree/main/patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "\n",
    "system_prompt_generator = SystemPromptGenerator(\n",
    "    background=[\n",
    "        'This assistant is a general-purpose AI designed to be helpful and friendly.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Understand the user\\'s input and provide a relevant response.',\n",
    "        'Respond to the user.'\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be friendly and respectful in all interactions.',\n",
    "        'Always answer in rhyming verse.'\n",
    "    ]\n",
    ")\n",
    "\n",
    "Console().print(system_prompt_generator.generate_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have generated the following system prompt:\n",
    "\n",
    "``` markdown\n",
    "# IDENTITY and PURPOSE\n",
    "- This assistant is a general-purpose AI designed to be helpful and friendly.\n",
    "\n",
    "# INTERNAL ASSISTANT STEPS\n",
    "- Understand the user's input and provide a relevant response.\n",
    "- Respond to the user.\n",
    "\n",
    "# OUTPUT INSTRUCTIONS\n",
    "- Provide helpful and relevant information to assist the user.\n",
    "- Be friendly and respectful in all interactions.\n",
    "- Always answer in rhyming verse.\n",
    "- Always respond using the proper JSON schema.\n",
    "- Always use the available additional information and context to enhance the response.\n",
    "```\n",
    "\n",
    "Note how the last two output instructions are not part of the developer's specification, but are automatically added by the framework to increase reliability in the system prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the system prompt, and thus essentially the behavior and purpose of the chatbot, it makes sense to define an initial memory with a message from the assistant to the user. This step is completely optional however as the `BaseAgent` that we will be using later has a check for this and will automatically create an empty memory if none is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
    "\n",
    "memory = AgentMemory()\n",
    "initial_memory = [\n",
    "    {'role': 'assistant', 'content': 'How do you do? What can I do for you? Tell me, pray, what is your need today?'}\n",
    "]\n",
    "memory.load(initial_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a custom chatbot. Either by using the `BaseAgent` class, or by extending it. Since this is a simple usecase, let's look at what it will look like if we simply use the class. In the code below, you can either specify your API key directly in the code or use an environment variable to store it.\n",
    "\n",
    "In this instance, I will use the OpenAI client with gpt-3.5-turbo. However, you can choose other clients such as **Anthropic**, **Mistral**, **Groq**, etc... For a full list, check out the [Instructor library docs](https://github.com/jxnl/instructor). Changing the client is as simple as changing the import statement, defining the client, and changing the `model` parameter to a model that is supported by that client (so, for example `llama3-70b-8192` on **Groq**)\n",
    "\n",
    "First, we'll set up the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "if not API_KEY:\n",
    "    # Get the environment variable\n",
    "    API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in the environment variable OPENAI_API_KEY.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up the patched `Instructor` client. This is what takes the `Pydantic` models and uses them for input validation and output generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI(api_key=API_KEY))\n",
    "\n",
    "agent = BaseAgent(\n",
    "    config=BaseAgentConfig(\n",
    "        client=client,\n",
    "        system_prompt_generator=system_prompt_generator,\n",
    "        model='gpt-3.5-turbo',\n",
    "        memory=memory,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Groq, for example would look like this:\n",
    "# import groq\n",
    "# client = instructor.from_groq(groq.Client(api_key=[YOUR API KEY]))\n",
    "# agent = BaseAgent(\n",
    "#     config=BaseAgentConfig(\n",
    "#         model='llama3-70b-8192',\n",
    "#         ...\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the chatbot. Let's start by printing the initial message, followed by a simple chat-loop. Personally, I like to have /exit and /quit as commands to exit the chatbot, but you can change this to whatever you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Agent: {initial_memory[0][\"content\"]}')\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input.lower() in ['/exit', '/quit']:\n",
    "        print('Exiting chat...')\n",
    "        break\n",
    "    \n",
    "    response = agent.run(agent.input_schema(chat_message=user_input))\n",
    "    print(f'Agent: {response.chat_message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behind the scenes\n",
    "\n",
    "So, what is happening behind the scenes when we run the chatbot? Let's dissect the `BaseAgent` and understand how it works.\n",
    "\n",
    "First off, as mentioned before, each tool and each agent has an **input schema** and an **output schema**.\n",
    "\n",
    "These schemas all extend from what is called the `BaseIOSchema` class. This class itself is a Pydantic model with some predefined methods to facilitate storing a structured response in memory and to facilitate printing the response to the console using the `rich` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from rich.json import JSON\n",
    "\n",
    "class BaseIOSchema(BaseModel):\n",
    "    \"\"\"\n",
    "    Base class for input and output schemas for chat agents.\n",
    "    \"\"\"\n",
    "    def __str__(self):\n",
    "        return self.model_dump_json()\n",
    "    \n",
    "    def __rich__(self):\n",
    "        json_str = self.model_dump_json()\n",
    "        return JSON(json_str)\n",
    "    \n",
    "class BaseAgentInputSchema(BaseIOSchema):\n",
    "    chat_message: str = Field(\n",
    "        ...,\n",
    "        description='The chat message exchanged between the user and the chat agent. '\n",
    "                    'This represents the message sent by the user.'\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        title = 'BaseAgentInputSchema'\n",
    "        description = 'This schema represents the user input message exchanged between the user and the chat agent.'\n",
    "        json_schema_extra = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "class BaseAgentOutputSchema(BaseIOSchema):\n",
    "    chat_message: str = Field(\n",
    "        ...,\n",
    "        description='The chat message exchanged between the user and the chat agent. '\n",
    "                    'This contains the markdown-enabled response generated by the chat agent.'\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        title = 'BaseAgentOutputSchema'\n",
    "        description = 'This schema represents the response message exchanged between the user and the chat agent.'\n",
    "        json_schema_extra = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, you can see that the `BaseAgentInputSchema` and `BaseAgentOutputSchema` both:\n",
    "- Extend from `BaseIOSchema`\n",
    "- Have a `chat_message` field with a `description` property \n",
    "- Have a Config class with a `title`, `description`, and `json_schema_extra` property.\n",
    "\n",
    "Let's analyze why these title and description properties are important, by looking at what will be presented to the LLM model when we run the chatbot. We can do this by simply dumping one of the schemas to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(BaseAgentOutputSchema.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"description\": \"This schema represents the response message exchanged between the user and the chat agent.\",\n",
    "  \"properties\": {\n",
    "    \"chat_message\": {\n",
    "      \"description\": \"The chat message exchanged between the user and the chat agent. This contains the markdown-enabled response generated by the chat agent.\",\n",
    "      \"title\": \"Chat Message\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\n",
    "    \"chat_message\"\n",
    "  ],\n",
    "  \"title\": \"BaseAgentOutputSchema\",\n",
    "  \"type\": \"object\"\n",
    "}\n",
    "```\n",
    "\n",
    "This is what the LLM model will see and be constricted by when generating a response. Additionally, this allows for easy generation of documentation as well since these properties are generally accepted by most documentation generators. For example by using [sphinx-pydantic](https://sphinx-pydantic.readthedocs.io/en/latest/).\n",
    "\n",
    "Thus, changing the title and description to be more clear, descriptive and precise is encouraged both to improve & fine-tune the agent's performance, but also to improve the documentation of the agent.\n",
    "\n",
    "Note that even though in the base chat agent both the input and output schemas have a `chat_message` field, this is not a requirement. We can easily specify any schema we like as the input or the output schema.\n",
    "\n",
    "For example, we can even have a nested schema with enums, lists, and more complex structures as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class YelpCategory(Enum):\n",
    "    ITALIAN = \"italian\"\n",
    "    MEXICAN = \"mexican\"\n",
    "    PIZZA = \"pizza\"\n",
    "    SUSHI = \"sushi\"\n",
    "    CHINESE = \"chinese\"\n",
    "    INDIAN = \"indian\"\n",
    "    THAI = \"thai\"\n",
    "    FRENCH = \"french\"\n",
    "    GREEK = \"greek\"\n",
    "    JAPANESE = \"japanese\"\n",
    "    KOREAN = \"korean\"\n",
    "    VIETNAMESE = \"vietnamese\"\n",
    "    AMERICAN = \"american\"\n",
    "    BBQ = \"bbq\"\n",
    "    BURGERS = \"burgers\"\n",
    "    SEAFOOD = \"seafood\"\n",
    "    STEAKHOUSES = \"steakhouses\"\n",
    "    VEGAN = \"vegan\"\n",
    "    VEGETARIAN = \"vegetarian\"\n",
    "\n",
    "class PriceRange(Enum):\n",
    "    ONE = \"1\"\n",
    "    TWO = \"2\"\n",
    "    THREE = \"3\"\n",
    "    FOUR = \"4\"\n",
    "\n",
    "class YelpSearchToolInputSchema(BaseIOSchema):\n",
    "    location: str = Field(..., description=\"Location to search for food.\")\n",
    "    term: Optional[str] = Field(None, description=\"Search term (e.g., 'pizza', 'sushi').\")\n",
    "    categories: Optional[List[YelpCategory]] = Field(None, description=\"Categories to filter by (e.g., 'italian, mexican').\")\n",
    "    price: Optional[List[PriceRange]] = Field(None, description=\"Price range to filter by (e.g., '1', '2', '3', '4'). Can be multiple. 1 is cheap. 2 and 3 are mid-range. 4 is the most high-end.\")\n",
    "    open_now: Optional[bool] = Field(False, description=\"Filter for businesses that are open now.\")\n",
    "    limit: Optional[int] = Field(10, description=\"Number of results to return.\")\n",
    "\n",
    "    class Config:\n",
    "        title = \"YelpSearchTool\"\n",
    "        description = \"Tool for searching for food using the Yelp API. Returns a list of businesses with details such as name, rating, and address.\"\n",
    "        json_schema_extra = {\n",
    "            \"title\": title,\n",
    "            \"description\": description\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting things to note here:\n",
    "- The price ranges and categories are defined as an enum, which means that the only valid values are the ones specified in the enum.\n",
    "- The description of the `price_range` field lists what the values mean, which is important for the model to understand the context of the input. This essentially replaces the need for a prompt or few-show examples in the traditional sense.\n",
    "- If this is not sufficient, [Pydantic examples](https://docs.pydantic.dev/latest/concepts/fields/#customizing-json-schema) can still be added as well per property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the BaseAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import Field, create_model\n",
    "from atomic_agents.agents.base_agent import BaseIOSchema, BaseAgent, BaseAgentConfig\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo\n",
    "from atomic_agents.lib.tools.base_tool import BaseTool\n",
    "from atomic_agents.lib.utils.format_tool_message import format_tool_message\n",
    "\n",
    "class ToolInterfaceAgentConfig(BaseAgentConfig):\n",
    "    tool_instance: BaseTool\n",
    "    return_raw_output: bool = False\n",
    "\n",
    "class ToolInputModel(BaseIOSchema):\n",
    "    tool_input: str = Field(..., description=\"Tool input. Presented as a single question or instruction\")\n",
    "\n",
    "    class Config:\n",
    "        title = \"Default Tool\"\n",
    "        description = \"Default tool description\"\n",
    "        json_schema_extra = {\n",
    "            \"title\": \"Default Tool\",\n",
    "            \"description\": \"Default tool description\"\n",
    "        }\n",
    "\n",
    "class ToolInterfaceAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    A specialized chat agent designed to interact with a specific tool.\n",
    "\n",
    "    This agent extends the BaseAgent to include functionality for interacting with a tool instance.\n",
    "    It generates system prompts, handles tool input and output, and can optionally return raw tool output.\n",
    "\n",
    "    Attributes:\n",
    "        tool_instance: The instance of the tool this agent will interact with.\n",
    "        return_raw_output (bool): Whether to return the raw output from the tool.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ToolInterfaceAgentConfig):\n",
    "        \"\"\"\n",
    "        Initializes the ToolInterfaceAgent.\n",
    "\n",
    "        Args:\n",
    "            config (ToolInterfaceAgentConfig): Configuration for the tool interface agent.\n",
    "        \"\"\"\n",
    "        super().__init__(config=config)\n",
    "        \n",
    "        self.tool_instance = config.tool_instance\n",
    "        self.return_raw_output = config.return_raw_output\n",
    "        \n",
    "        # Create a new model with the updated schema\n",
    "        self.input_schema = create_model(\n",
    "            self.tool_instance.tool_name,\n",
    "            tool_input=(str, Field(..., description=f\"{self.tool_instance.tool_name} tool input. Presented as a single question or instruction\", alias=f'tool_input_{self.tool_instance.tool_name}')),\n",
    "            __base__=ToolInputModel\n",
    "        )\n",
    "        \n",
    "        # Manually set the configuration attributes\n",
    "        self.input_schema.model_config['title'] = self.tool_instance.tool_name\n",
    "        self.input_schema.model_config['description'] = self.tool_instance.tool_description\n",
    "        self.input_schema.model_config['json_schema_extra'] = {\n",
    "            'title': self.tool_instance.tool_name,\n",
    "            'description': self.tool_instance.tool_description\n",
    "        }\n",
    "        \n",
    "        if self.return_raw_output:\n",
    "            self.output_schema = self.tool_instance.output_schema\n",
    "            \n",
    "        self.system_prompt_generator = SystemPromptGenerator(\n",
    "            background=[\n",
    "                f\"This AI agent is designed to interact with the {self.tool_instance.tool_name} tool.\",\n",
    "                f\"Tool description: {self.tool_instance.tool_description}\"\n",
    "            ],\n",
    "            steps=[\n",
    "                \"Get the user input.\",\n",
    "                \"Convert the input to the proper parameters to call the tool.\",\n",
    "                \"Call the tool with the parameters.\",\n",
    "                \"Respond to the user\"\n",
    "            ],\n",
    "            output_instructions=[\n",
    "                \"Make sure the tool call will maximize the utility of the tool in the context of the user input.\",\n",
    "                \"Process the output of the tool into a human readable format and/or use it to respond to the user input.\" if self.return_raw_output else \"Return the raw output of the tool.\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def _get_and_handle_response(self):\n",
    "        \"\"\"\n",
    "        Handles obtaining and processing the response from the tool.\n",
    "\n",
    "        This method gets the response from the tool, formats the tool input, adds it to memory,\n",
    "        runs the tool, and processes the tool output. If `return_raw_output` is True, it returns\n",
    "        the raw tool output; otherwise, it processes the output and returns the response.\n",
    "        \n",
    "        Returns:\n",
    "            BaseModel: The processed response or raw tool output.\n",
    "        \"\"\"\n",
    "        tool_input = self.get_response(response_model=self.tool_instance.input_schema)\n",
    "        formatted_tool_input = format_tool_message(tool_input)\n",
    "        \n",
    "        self.memory.add_message('assistant', 'TOOL CALL: ' + json.dumps(formatted_tool_input))\n",
    "        tool_output = self.tool_instance.run(tool_input)\n",
    "        self.memory.add_message('assistant', 'TOOL RESPONSE: ' + tool_output.model_dump_json())\n",
    "        \n",
    "        if self.return_raw_output:\n",
    "            return tool_output\n",
    "        \n",
    "        self.memory.add_message('assistant', 'I will now formulate a response for the user based on the tool output.')\n",
    "        response = self.get_response(response_model=self.output_schema)        \n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, another way to create a new agent is by extending the `BaseAgent` class. This allows for more flexibility and customization. Let's look at an example where we extend the `BaseAgent` class to create an agent of which the output will always match the required input for a tool. To achieve this and get both the tool call and tool response in the memory, we will want to override the method `_get_and_handle_response`. Additionally, we will want to generate the input schema **dynamically** in order to be able to use any tool we want with this new agent.\n",
    "\n",
    "A simple example of how to use this ToolInterfaceAgent could be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import instructor\n",
    "import openai\n",
    "from rich.console import Console\n",
    "\n",
    "from atomic_agents.agents.tool_interface_agent import ToolInterfaceAgent, ToolInterfaceAgentConfig\n",
    "from atomic_agents.lib.tools.search.searxng_tool import SearxNGTool, SearxNGToolConfig\n",
    "\n",
    "def initialize_searxng_tool():\n",
    "    \"\"\"\n",
    "    Initialize the SearxNGTool with configuration.\n",
    "    \"\"\"\n",
    "    base_url = os.getenv('SEARXNG_BASE_URL')\n",
    "    config = SearxNGToolConfig(base_url=base_url, max_results=10)\n",
    "    return SearxNGTool(config)\n",
    "\n",
    "def initialize_agent(client, searxng_tool):\n",
    "    \"\"\"\n",
    "    Initialize the ToolInterfaceAgent with the given client and SearxNGTool.\n",
    "    \"\"\"\n",
    "    agent_config = ToolInterfaceAgentConfig(\n",
    "        client=client,\n",
    "        model='gpt-3.5-turbo',\n",
    "        tool_instance=searxng_tool,\n",
    "        return_raw_output=False\n",
    "    )\n",
    "    return ToolInterfaceAgent(config=agent_config)\n",
    "\n",
    "def main():\n",
    "    console = Console()\n",
    "    client = instructor.from_openai(\n",
    "    openai.OpenAI(\n",
    "            base_url='http://localhost:1234/v1'\n",
    "        )\n",
    "    )\n",
    "    searxng_tool = initialize_searxng_tool()\n",
    "    agent = initialize_agent(client, searxng_tool)\n",
    "\n",
    "    console.print(\"ToolInterfaceAgent with SearxNGTool is ready.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input('You: ')\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print('Exiting chat...')\n",
    "            break\n",
    "        \n",
    "        # Fix this\n",
    "        response = agent.run(agent.input_schema(tool_input=user_input))\n",
    "        console.print(f'Agent: {response.chat_message}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For now, that's it! While this guide is by no means complete, it should serve as a decent starting point for anyone looking to get started with **Atomic Agents**. If you have any questions, feel free to reach out to me! I'm always happy to help out and answer any questions you might have. If you want to contribute to the project, feel free to open a pull request on the [GitHub repository](https://github.com/KennyVaneetvelde/atomic_agents). Any help is greatly appreciated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If this article sparks your interest and you have any business inquiries, feel free to get in touch with me on [LinkedIn](https://www.linkedin.com/in/kennyvaneetvelde/). As an experienced life-long full-stack developer and course author with a grand fascination for what makes things ‘tick’ and a love for AI that started in my early teens, I am absolutely certain I can assist with anything from coaching to product development to bespoke consultancy services."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
