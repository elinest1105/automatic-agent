{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# Custom Chatbot with Atomic Agents\n",
     "\n",
     "This example demonstrates how to create a custom chatbot with a custom personality using the Atomic Agents library.\n",
     "\n",
     "## Project Information\n",
     "\n",
     "This project showcases how to build a chatbot with a unique personality using the Atomic Agents library. The chatbot is designed to be helpful and friendly, responding to user inputs in rhyming verse, preferably in alexandrine verse.\n",
     "\n",
     "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennyVaneetvelde/atomic_agents/blob/main/examples/notebooks/basic_custom_chatbot.ipynb#)\n"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Install necessary packages\n",
     "!pip install atomic-agents openai instructor"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
     "from atomic_agents.lib.components.chat_memory import ChatMemory\n",
     "from atomic_agents.agents.base_chat_agent import BaseChatAgent\n",
     "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo\n",
     "import instructor\n",
     "import openai"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Define System Prompt Information\n",
     "\n",
     "We will define the system prompt information including background, steps, and output instructions."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
     "system_prompt = SystemPromptInfo(\n",
     "    background=[\n",
     "        'This assistant is a general-purpose AI designed to be helpful and friendly.',\n",
     "    ],\n",
     "    steps=[\n",
     "        'Understand the user\\'s input and provide a relevant response.',\n",
     "        'Respond to the user.'\n",
     "    ],\n",
     "    output_instructions=[\n",
     "        'Provide helpful and relevant information to assist the user.',\n",
     "        'Be friendly and respectful in all interactions.',\n",
     "        'Always answer in rhyming verse. Preferably in alexandrine verse.'\n",
     "    ]\n",
     ")\n",
     "system_prompt_generator = SystemPromptGenerator(system_prompt)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Initialize Chat Memory\n",
     "\n",
     "We will initialize the chat memory to store conversation history and load an initial greeting message."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
     "memory = ChatMemory()\n",
     "initial_memory = [\n",
     "    {'role': 'assistant', 'content': 'How do you do? What can I do for you? Tell me, pray, what is your need today?'}\n",
     "]\n",
     "memory.load(initial_memory)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Create Chat Agent\n",
     "\n",
     "We will create a chat agent with the specified model, system prompt generator, and memory."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
     "agent = BaseChatAgent(\n",
     "    client=instructor.from_openai(openai.OpenAI()), \n",
     "    system_prompt_generator=system_prompt_generator,\n",
     "    model='gpt-3.5-turbo',\n",
     "    memory=memory,\n",
     ")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Main Chat Loop\n",
     "\n",
     "We will create a main chat loop for testing the chat agent."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 6,
    "metadata": {},
    "outputs": [],
    "source": [
     "print(f'Agent: {initial_memory[0][\"content\"]}')\n",
     "\n",
     "while True:\n",
     "    user_input = input('You: ')\n",
     "    if user_input.lower() in ['/exit', '/quit']:\n",
     "        print('Exiting chat...')\n",
     "        break\n",
     "\n",
     "    response = agent.run(user_input)\n",
     "    print(f'Agent: {response.response}')"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
     "nbconvert_exporter": "python",
     "pygments_lexer": "ipython3",
     "version": "3.12.3"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 4
 }
 