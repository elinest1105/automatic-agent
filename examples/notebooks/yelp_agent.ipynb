{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Restaurant Finder Agent\n",
    "\n",
    "This notebook demonstrates how to create a restaurant finder agent using the Atomic Agents library. The agent will interact with users to gather their preferences and search for restaurants using the Yelp API.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennyVaneetvelde/atomic_agents/blob/main/examples/notebooks/yelp_agent.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before proceeding with this notebook, it is highly recommended to read up on the basics of the following libraries:\n",
    "\n",
    "- **Pydantic**: A data validation and settings management library using Python type annotations. You can find more information and documentation at [Pydantic GitHub](https://github.com/pydantic/pydantic).\n",
    "- **Instructor**: A Python library that simplifies working with structured outputs from large language models (LLMs). It provides a user-friendly API to manage validation, retries, and streaming responses. More details can be found at [Instructor GitHub](https://github.com/jxnl/instructor).\n",
    "\n",
    "Understanding these libraries will help you make the most of this library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install `atomic-agents`, `openai`, and `instructor` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install atomic-agents openai instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries\n",
    "\n",
    "We will import the necessary libraries for creating the restaurant finder agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import Union\n",
    "from pydantic import BaseModel, Field\n",
    "import instructor\n",
    "import openai\n",
    "from rich.console import Console\n",
    "\n",
    "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo\n",
    "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentOutputSchema, BaseAgentConfig\n",
    "from atomic_agents.lib.tools.yelp_restaurant_finder_tool import YelpSearchTool, YelpSearchToolConfig, YelpSearchToolSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define System Prompt Information\n",
    "\n",
    "Define the system prompt information including background, steps, and output instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt information including background, steps, and output instructions\n",
    "system_prompt = SystemPromptInfo(\n",
    "    background=[\n",
    "        'This assistant is a restaurant finder AI designed to help users find the best restaurants based on their preferences by asking clarifying questions.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Greet the user and introduce yourself as a restaurant finder assistant.',\n",
    "        'Inspect the required Yelp schema and identify the necessary filters.',\n",
    "        'Ask the user questions to gather information for each filter until all required information is clear.',\n",
    "        'Use the chat responses to gather all necessary information from the user.',\n",
    "        'Once all required information is gathered, use the YelpSearchTool schema to search Yelp for restaurants.',\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Always use the chosen schema as output',\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be friendly and respectful in all interactions.',\n",
    "        'Ensure that the chat responses are used to ask clarifying questions and gather information, and the Yelp schema is used to perform the actual search.'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Components\n",
    "\n",
    "Initialize the system prompt generator, chat memory, and console for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the system prompt generator with the defined system prompt and dynamic info providers\n",
    "system_prompt_generator = SystemPromptGenerator(system_prompt)\n",
    "\n",
    "# Initialize chat memory to store conversation history\n",
    "memory = AgentMemory()\n",
    "# Define initial memory with a greeting message from the assistant\n",
    "initial_memory = [\n",
    "    {'role': 'assistant', 'content': 'Hello, can I help you find a restaurant?'}\n",
    "]\n",
    "# Load the initial memory into the chat memory\n",
    "memory.load(initial_memory)\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize the Client\n",
    "\n",
    "Initialize the client using the `instructor` library. For all supported clients such as Anthropic & Gemini, refer to the `instructor` library documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = instructor.from_openai(openai.OpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize the YelpSearchTool\n",
    "\n",
    "Set up the YelpSearchTool with the necessary configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the YelpSearchTool\n",
    "yelp_tool = YelpSearchTool(YelpSearchToolConfig(api_key=os.getenv('YELP_API_KEY'), max_results=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Define a Custom Response Schema\n",
    "\n",
    "Create a custom response schema that can handle both chat responses and Yelp search tool responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom response schema that can handle both chat responses and Yelp search tool responses\n",
    "class ResponseSchema(BaseModel):\n",
    "    chosen_schema: Union[BaseAgentOutputSchema, YelpSearchToolSchema] = Field(..., description='The response from the chat agent.')\n",
    "\n",
    "    class Config:\n",
    "        title = 'OutputSchema'\n",
    "        description = 'The response schema for the chat agent.'\n",
    "        json_schema_extra = {\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create the Chat Agent\n",
    "\n",
    "Create a chat agent with the specified model, system prompt generator, and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat agent with the specified model, system prompt generator, and memory\n",
    "agent = BaseAgent(\n",
    "    config=BaseAgentConfig(\n",
    "        client=client, \n",
    "        system_prompt_generator=system_prompt_generator,\n",
    "        model='gpt-3.5-turbo',\n",
    "        memory=memory,\n",
    "        output_schema=OutputSchema\n",
    "    )\n",
    ")\n",
    "\n",
    "console.print(\"BaseAgent with YelpSearchTool is ready.\")\n",
    "console.print(f'Agent: {initial_memory[0][\"content\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Run the Agent\n",
    "\n",
    "Start the agent to interact with the user. The agent will ask for user input, process it, and provide responses based on the gathered information.\n",
    "Try telling it you would like some pizza, it should ask for your location and other information until it feels it can properly call the Yelp API with the information it has gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print('Exiting chat...')\n",
    "        break\n",
    "\n",
    "    response = agent.run(agent.input_schema(chat_message=user_input).model_dump())\n",
    "    \n",
    "    # Check the type of the response schema\n",
    "    if isinstance(response.chosen_schema, YelpSearchToolSchema):\n",
    "        output = yelp_tool.run(response.chosen_schema)\n",
    "        agent.memory.add_message('system', f'The following information was found: {output.results}\\n\\n Please summarize the results for the user.')\n",
    "        output = agent.run().chosen_schema.chat_message\n",
    "    else:\n",
    "        output = response.chosen_schema.chat_message\n",
    "        \n",
    "    console.print(f'Agent: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to create a restaurant finder agent using the Atomic Agents library. The agent interacts with users to gather their preferences and searches for restaurants using the Yelp API. You can further customize the agent and enhance its capabilities based on your requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
