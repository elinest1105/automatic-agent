{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Tutorial: Basic Custom Chatbot using Atomic Agents\n",
    "\n",
    "This quickstart tutorial demonstrates how to create a custom chatbot with a unique personality using the Atomic Agents library. The chatbot will respond to user inputs in rhyming verse.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennyVaneetvelde/atomic_agents/blob/main/examples/notebooks/quickstart.ipynb#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "Before proceeding with this notebook, it is highly recommended to read up on the basics of the following libraries:\n",
    "\n",
    "- **Pydantic**: A data validation and settings management library using Python type annotations. You can find more information and documentation at [Pydantic GitHub](https://github.com/pydantic/pydantic).\n",
    "- **Instructor**: A Python library that simplifies working with structured outputs from large language models (LLMs). It provides a user-friendly API to manage validation, retries, and streaming responses. More details can be found at [Instructor GitHub](https://github.com/jxnl/instructor).\n",
    "\n",
    "Understanding these libraries will help you make the most of this library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install `atomic-agents`, `openai`, and `instructor` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install atomic-agents openai instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries\n",
    "\n",
    "We will import the necessary libraries for creating the chatbot. Each library serves a specific purpose:\n",
    "- `ChatMemory`: Manages the chat history.\n",
    "- `BaseChatAgent`: The base class to create a custom chatbot. Can be extended for additional functionality if needed.\n",
    "- `SystemPromptGenerator` and `SystemPromptInfo`: To define and generate system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import instructor\n",
    "import openai\n",
    "from atomic_agents.lib.components.chat_memory import ChatMemory\n",
    "from atomic_agents.agents.base_chat_agent import BaseChatAgent, BaseChatAgentConfig\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define System Prompt Information\n",
    "\n",
    "We will define the system prompt information including background, steps, and output instructions. This helps the chatbot understand how to respond to user inputs.\n",
    "In this example, we will define a system prompt that asks the chatbot to respond to user inputs in rhyming verse.\n",
    "\n",
    "The structuring of the system prompts in this library is loosely inspired by Patterns in the [Fabric library](https://github.com/danielmiessler/fabric/tree/main/patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemPromptInfo(\n",
    "    background=[\n",
    "        'This assistant is a general-purpose AI designed to be helpful and friendly.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Understand the user\\'s input and provide a relevant response.',\n",
    "        'Respond to the user.'\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be friendly and respectful in all interactions.',\n",
    "        'Always answer in rhyming verse.'\n",
    "    ]\n",
    ")\n",
    "system_prompt_generator = SystemPromptGenerator(system_prompt)\n",
    "\n",
    "from rich.markdown import Markdown\n",
    "Markdown(system_prompt_generator.generate_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Chat Memory\n",
    "\n",
    "We will initialize the chat memory to store conversation history and load an initial greeting message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemory()\n",
    "initial_memory = [\n",
    "    {'role': 'assistant', 'content': 'How do you do? What can I do for you? Tell me, pray, what is your need today?'}\n",
    "]\n",
    "memory.load(initial_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set Up API Key and Create Chat Agent\n",
    "\n",
    "To use the **OpenAI** API, you need to set up your API key. You can either enter it directly in the code or set it as an environment variable. Additionally, you can choose other clients such as **Anthropic**, **Mistral**, etc. For a full list, check out the [Instructor library docs](https://github.com/jxnl/instructor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# ENTER YOUR API KEY BELOW, OR SET IT AS AN ENVIRONMENT VARIABLE #\n",
    "##################################################################\n",
    "API_KEY = ''\n",
    "if not API_KEY:\n",
    "    # Get the environment variable\n",
    "    API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in the environment variable OPENAI_API_KEY.')\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI(api_key=API_KEY))\n",
    "\n",
    "agent = BaseChatAgent(\n",
    "    config=BaseChatAgentConfig(\n",
    "        client=client,\n",
    "        system_prompt_generator=system_prompt_generator,\n",
    "        model='gpt-3.5-turbo',\n",
    "        memory=memory,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Main Chat Loop\n",
    "\n",
    "We will create a main chat loop for testing the chat agent. This loop will allow you to interact with the chatbot in real-time.\n",
    "To exit the loop, type `/exit` or `/quit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Agent: {initial_memory[0][\"content\"]}')\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input.lower() in ['/exit', '/quit']:\n",
    "        print('Exiting chat...')\n",
    "        break\n",
    "\n",
    "    # Note: The .model_dump() method is ONLY necessary in an ipython notebook.\n",
    "    # In a normal Python script, you can simply pass the input_schema() run() method like so:\n",
    "    # response = agent.run(agent.input_schema(chat_input=user_input))\n",
    "    # The reason for this is unknown to me and I have not been able to find any documentation on it.\n",
    "    response = agent.run(agent.input_schema(chat_input=user_input).model_dump())\n",
    "    print(f'Agent: {response.response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
