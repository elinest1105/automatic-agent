{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Tutorial: Basic Custom Chatbot using Atomic Agents\n",
    "\n",
    "This quickstart tutorial demonstrates how to create a custom chatbot with a unique personality using the Atomic Agents library. The chatbot will respond to user inputs in rhyming verse.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennyVaneetvelde/atomic_agents/blob/main/examples/notebooks/basic_custom_chatbot.ipynb#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install `atomic-agents`, `openai`, and `instructor` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install atomic-agents openai instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries\n",
    "\n",
    "We will import the necessary libraries for creating the chatbot. Each library serves a specific purpose:\n",
    "- `ChatMemory`: Manages the chat history.\n",
    "- `BaseChatAgent`: The base class to create a custom chatbot. Can be extended for additional functionality if needed.\n",
    "- `SystemPromptGenerator` and `SystemPromptInfo`: To define and generate system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import instructor\n",
    "import openai\n",
    "from atomic_agents.lib.components.chat_memory import ChatMemory\n",
    "from atomic_agents.agents.base_chat_agent import BaseChatAgent\n",
    "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator, SystemPromptInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define System Prompt Information\n",
    "\n",
    "We will define the system prompt information including background, steps, and output instructions. This helps the chatbot understand how to respond to user inputs.\n",
    "In this example, we will define a system prompt that asks the chatbot to respond to user inputs in rhyming verse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemPromptInfo(\n",
    "    background=[\n",
    "        'This assistant is a general-purpose AI designed to be helpful and friendly.',\n",
    "    ],\n",
    "    steps=[\n",
    "        'Understand the user\\'s input and provide a relevant response.',\n",
    "        'Respond to the user.'\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        'Provide helpful and relevant information to assist the user.',\n",
    "        'Be friendly and respectful in all interactions.',\n",
    "        'Always answer in rhyming verse.'\n",
    "    ]\n",
    ")\n",
    "system_prompt_generator = SystemPromptGenerator(system_prompt)\n",
    "\n",
    "from rich.markdown import Markdown\n",
    "Markdown(system_prompt_generator.generate_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Chat Memory\n",
    "\n",
    "We will initialize the chat memory to store conversation history and load an initial greeting message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemory()\n",
    "initial_memory = [\n",
    "    {'role': 'assistant', 'content': 'How do you do? What can I do for you? Tell me, pray, what is your need today?'}\n",
    "]\n",
    "memory.load(initial_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set Up API Key and Create Chat Agent\n",
    "\n",
    "To use the **OpenAI** API, you need to set up your API key. You can either enter it directly in the code or set it as an environment variable. Additionally, you can choose other clients such as **Anthropic**, **Mistral**, etc. For a full list, check out the [Instructor library docs](https://github.com/jxnl/instructor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# ENTER YOUR API KEY BELOW, OR SET IT AS AN ENVIRONMENT VARIABLE #\n",
    "##################################################################\n",
    "API_KEY = ''\n",
    "if not API_KEY:\n",
    "    # Get the environment variable\n",
    "    API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError('API key is not set. Please set the API key as a static variable or in the environment variable OPENAI_API_KEY.')\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI(api_key=API_KEY))\n",
    "\n",
    "agent = BaseChatAgent(\n",
    "    client=client, \n",
    "    system_prompt_generator=system_prompt_generator,  # Set now\n",
    "    model='gpt-3.5-turbo',\n",
    "    memory=memory,  # Set now\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Main Chat Loop\n",
    "\n",
    "We will create a main chat loop for testing the chat agent. This loop will allow you to interact with the chatbot in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Agent: {initial_memory[0][\"content\"]}')\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input.lower() in ['/exit', '/quit']:\n",
    "        print('Exiting chat...')\n",
    "        break\n",
    "\n",
    "    response = agent.run(user_input)\n",
    "    print(f'Agent: {response.response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
